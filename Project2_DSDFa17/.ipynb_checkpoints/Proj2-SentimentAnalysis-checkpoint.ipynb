{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training\"):\n",
    "    directory = \"data_training/\" + c\n",
    "    for file in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + file)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "        e['__FileID__'] = file\n",
    "        e['__CLASS__'] = c\n",
    "        d.append(e)\n",
    "d = d[:len(d)//20] + d[19*len(d)//20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(one, two):\n",
    "    count = 0\n",
    "    for cat, dog in zip(one, two):\n",
    "        if (cat == dog):\n",
    "            count += 1\n",
    "    print(\"Accuracy: \", count / len(one))\n",
    "    \n",
    "def accuracy_no_print(one, two):\n",
    "    count = 0\n",
    "    for cat, dog in zip(one, two):\n",
    "        if (cat == dog):\n",
    "            count += 1\n",
    "    return count / len(one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from d - make sure to fill all the nan values with zeros.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "df = df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     !     \"   #1   #2  #@%$^  $1000  $20  $200  $21  $25    ...      zone  \\\n",
      "0  3.0  10.0  0.0  0.0    0.0    0.0  0.0   0.0  0.0  0.0    ...       0.0   \n",
      "1  0.0   2.0  0.0  0.0    0.0    0.0  0.0   0.0  0.0  0.0    ...       0.0   \n",
      "2  0.0   0.0  0.0  0.0    0.0    0.0  0.0   0.0  0.0  0.0    ...       0.0   \n",
      "3  0.0  20.0  0.0  0.0    0.0    0.0  0.0   0.0  0.0  0.0    ...       0.0   \n",
      "4  0.0   4.0  0.0  0.0    0.0    0.0  0.0   0.0  0.0  0.0    ...       0.0   \n",
      "\n",
      "   zoologist  zoom-ins  zoom-outs  zorro  zuko  zurg's  zwick  zwick's  \\\n",
      "0        0.0       0.0        0.0    0.0   0.0     0.0    0.0      0.0   \n",
      "1        0.0       0.0        0.0    0.0   0.0     0.0    0.0      0.0   \n",
      "2        0.0       0.0        0.0    0.0   0.0     0.0    0.0      0.0   \n",
      "3        0.0       0.0        0.0    0.0   0.0     0.0    0.0      0.0   \n",
      "4        0.0       0.0        0.0    0.0   0.0     0.0    0.0      0.0   \n",
      "\n",
      "   zwigoff's  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "\n",
      "[5 rows x 14010 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Sample 80% of your dataframe to be the training data\n",
    "\n",
    "* Let the remaining 20% be the validation data (you can filter out the indicies of the original dataframe that weren't selected for the training data)\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = df.sample(frac=.8)\n",
    "#cant figure out validation...\n",
    "validation = df\n",
    "for thing in list(training.index.values):\n",
    "    validation = validation.drop(thing)\n",
    "    \n",
    "#training, validation = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataframe for both training and validation data into x and y dataframes - where y contains the labels and x contains the words\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = training['__CLASS__']\n",
    "x_train = training.drop('__CLASS__', 1, inplace=True)\n",
    "x_train = training.drop('__FileID__', 1)\n",
    "y_numbers = []\n",
    "for elem in y_train:\n",
    "    y_numbers.append(int(elem == 'neg'))\n",
    "\n",
    "\n",
    "y_valid = y_train\n",
    "x_valid = validation\n",
    "try:\n",
    "    x_valid = validation.drop('__CLASS__', 1, inplace=True)\n",
    "    x_valid = validation.drop('__FileID__', 1)\n",
    "except KeyError:\n",
    "    pass\n",
    "y_numbersv = []\n",
    "for elem in y_valid:\n",
    "    y_numbersv.append(int(elem == 'neg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression\n",
    "* Use sklearn's linear_model.LogisticRegression() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(x_train, y_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5625\n"
     ]
    }
   ],
   "source": [
    "### Scoring the Model\n",
    "result1 = model.predict(x_valid)\n",
    "accuracy(result1, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_x_train = x_train.drop(\"the\", axis=1)\n",
    "other_x_train = other_x_train.drop(\"a\", axis=1)\n",
    "other_x_train = other_x_train.drop(\"an\", axis=1)\n",
    "\n",
    "other_model = sklearn.linear_model.LogisticRegression()\n",
    "other_model.fit(other_x_train, y_numbers)\n",
    "\n",
    "other_x_valid = x_valid.drop(\"the\", axis=1)\n",
    "other_x_valid = other_x_valid.drop(\"a\", axis=1)\n",
    "other_x_valid = other_x_valid.drop(\"an\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5625\n"
     ]
    }
   ],
   "source": [
    "result2 = other_model.predict(other_x_valid)\n",
    "\n",
    "accuracy(result2, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "* In the backward stepsize selection method, you can remove coefficients and the corresponding x columns, where the coefficient is more than a particular amount away from the mean - you can choose how far from the mean is reasonable.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.std.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001105854521\n",
      "0.0170294831451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = model.coef_[0]\n",
    "mean = np.mean(coefficients)\n",
    "sd = np.std(coefficients)\n",
    "\n",
    "print(mean)\n",
    "print(sd)\n",
    "\n",
    "to_remove = []\n",
    "\n",
    "for i in range(len(coefficients)):\n",
    "    num = coefficients[i]\n",
    "    if (num < mean - 2 * sd or num > mean + 2 * sd):\n",
    "        to_remove += [i]\n",
    "        \n",
    "x_train_2 = x_train\n",
    "x_valid_2 = x_valid\n",
    "        \n",
    "for thing in to_remove:\n",
    "    label = x_train.columns[thing]\n",
    "    x_train_2 = x_train_2.drop(label, axis=1)\n",
    "    x_valid_2 = x_valid_2.drop(label, axis=1)\n",
    "\n",
    "\n",
    "model_2 = sklearn.linear_model.LogisticRegression()\n",
    "model_2.fit(x_train_2, y_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.59375\n"
     ]
    }
   ],
   "source": [
    "result3 = model_2.predict(x_valid_2)\n",
    "accuracy(result3, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you select which features to remove? Why did that reduce overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We selected features to remove that do not have a particular positive or negative connotation so that the model would not think that these features were important to the overall positivity or negativity of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Decision Tree\n",
    "\n",
    "* Initialize your model as a decision tree with sklearn.\n",
    "* Fit the data and labels to the model.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "stanford_mascot = DecisionTreeClassifier() #no max depth, no max features, no max leaves\n",
    "stanford_mascot.fit(x_train, y_numbers) #fitting features to labels\n",
    "predictions = stanford_mascot.predict(x_valid) #accuracy score for the validation set, preparing to disown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Accuracy:  0.4375\n"
     ]
    }
   ],
   "source": [
    "accuracy(stanford_mascot.predict(x_train), y_numbers)\n",
    "accuracy(predictions, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters\n",
    "* To test out which value is optimal for a particular parameter, you can either loop through various values or look into sklearn.model_selection.GridSearchCV\n",
    "\n",
    "References:\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: (0.90625, 0.46875), 6: (0.953125, 0.4375), 7: (0.9765625, 0.46875), 8: (0.9921875, 0.5625), 9: (1.0, 0.53125), 10: (1.0, 0.53125), 11: (1.0, 0.53125), 12: (1.0, 0.53125), 13: (1.0, 0.4375), 14: (1.0, 0.4375), 15: (1.0, 0.53125), 16: (1.0, 0.5625), 17: (1.0, 0.46875), 18: (1.0, 0.4375), 19: (1.0, 0.53125), 20: (1.0, 0.4375), 21: (1.0, 0.53125), 22: (1.0, 0.4375), 23: (1.0, 0.4375), 24: (1.0, 0.53125), 25: (1.0, 0.5), 26: (1.0, 0.5), 27: (1.0, 0.53125), 28: (1.0, 0.53125), 29: (1.0, 0.5)}\n"
     ]
    }
   ],
   "source": [
    "depth = list(range(5, 30))\n",
    "accuracies = {}\n",
    "\n",
    "for deep in depth:\n",
    "    nice_firewood = DecisionTreeClassifier(max_depth = deep)\n",
    "    nice_firewood.fit(x_train, y_numbers)\n",
    "    training_acc = accuracy_no_print(nice_firewood.predict(x_train), y_numbers)\n",
    "    valid_acc = accuracy_no_print(nice_firewood.predict(x_valid), y_numbersv)\n",
    "    accuracies[deep] = (training_acc, valid_acc)\n",
    "\n",
    "print(accuracies) #8, 11, 15, 18, 20, 28 seem to be the best depths, so we'll use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaves = list(range(20, 40))\n",
    "depth = [8, 11, 15, 18, 20, 28]\n",
    "accuracies = {}\n",
    "\n",
    "for deep in depth:\n",
    "    for leaveses in leaves:\n",
    "        nice_firewood = DecisionTreeClassifier(max_depth = deep, max_leaf_nodes = leaveses)\n",
    "        nice_firewood.fit(x_train, y_numbers)\n",
    "        training_acc = accuracy_no_print(nice_firewood.predict(x_train), y_numbers)\n",
    "        valid_acc = accuracy_no_print(nice_firewood.predict(x_valid), y_numbersv)\n",
    "        accuracies[str(deep) + \" \" + str(leaveses)] = (training_acc, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 39 (1.0, 0.5625)\n"
     ]
    }
   ],
   "source": [
    "keys = list(accuracies.keys())\n",
    "chosen_one = 0\n",
    "result = accuracies[keys[0]]\n",
    "\n",
    "for key in keys:\n",
    "    if (result[1] < accuracies[key][1]):\n",
    "        chosen_one = key\n",
    "        result = accuracies[key]\n",
    "\n",
    "print(key, result) # max_depth = 8, max_leaves = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridsearch = GridSearchCV(estimator = DecisionTreeClassifier(max_depth = 8, max_leaf_nodes = 21), param_grid = {}, refit = True)\n",
    "gridsearch.fit(x_train, y_numbers)\n",
    "\n",
    "oski_tree_slayer = gridsearch.best_estimator_\n",
    "#oski_train = oski_tree_slayer.score(x_train, y_train)\n",
    "#oski_valid = oski_tree_slayer.score(x_valid, y_valid)\n",
    "values = oski_tree_slayer.predict(x_valid)\n",
    "\n",
    "accuracy(values, y_numbersv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for header in list(x_train):\n",
    "    summd = x_train[header].sum()\n",
    "    if (summd <= 40 or summd >= 100):\n",
    "        x_train.drop(header, axis = 1)\n",
    "        x_valid.drop(header, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaves = list(range(20, 40))\n",
    "depth = [8, 11, 15, 18, 20, 28]\n",
    "accuracies = {}\n",
    "\n",
    "for deep in depth:\n",
    "    for leaveses in leaves:\n",
    "        tree = DecisionTreeClassifier(max_depth = deep, max_leaf_nodes = leaveses)\n",
    "        tree.fit(x_train, y_numbers)\n",
    "        training_acc = accuracy_no_print(tree.predict(x_train), y_numbers)\n",
    "        valid_acc = accuracy_no_print(tree.predict(x_valid), y_numbersv)\n",
    "        accuracies[str(deep) + \" \" + str(leaveses)] = (training_acc, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(accuracies.keys())\n",
    "chosen_one = 0\n",
    "result = accuracies[keys[0]]\n",
    "\n",
    "for key in keys:\n",
    "    if (result[1] < accuracies[key][1]):\n",
    "        chosen_one = key\n",
    "        result = accuracies[key]\n",
    "\n",
    "print(key, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you choose which parameters to change and what value to give to them? Feel free to show a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We manually tried restricting depth and leaves, then used gridsearch to restrict features. The prior two increased test set accuracy, but for reasons not known to humankind the third actually decreased it. We thus decided to just drop any words that weren't used more than 20 times or used more than 100 across all texts, and tried restricting the depth and leaves. We ended up with \"8 21 (1.0, 0.625)\", which stands for 14 max depth, 30 max leaves, and a validation accuracy of roughly 62% (comeback?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a single decision tree so prone to overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are many features that a decision tree uses to fit to its training set, and since these features can be incredibly granular, decision trees will naturally learn to categorise its training data in a extremely specific fashion. This specificity fails to apply when a different data set is used, such as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Random Forest\n",
    "\n",
    "* Use sklearn's ensemble.RandomForestClassifier() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_numbers)\n",
    "\n",
    "predictions = model.predict(x_valid)\n",
    "accuracy(predictions, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomNumber = np.random.RandomState\n",
    "\n",
    "model = RandomForestClassifier(random_state=RandomNumber)\n",
    "model.fit(x_train, y_numbers)\n",
    "\n",
    "predictions = model.predict(x_valid)\n",
    "accuracy(predictions, y_numbersv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What parameters did you choose to change and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We chose random state to affect the way features were sampled. The more varied features we sampled, the less\" opportunity for overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a random forest classifier prevent overfitting better than a single decision tree?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is more generalized, so being to specific in a single dataset is lost in the noise of multiple trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
